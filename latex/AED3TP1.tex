\documentclass[a4paper]{article}

\setlength{\parskip}{0.1em}
\input{Algo1Macros}
\usepackage{caratula}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{pdfpages}
\usepackage{listings}

\lstset{basicstyle=\fontsize{8}{6}\selectfont\ttfamily,
    breaklines=true,
    numbers=left,
    showstringspaces=false,
	literate=
  {á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
  {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
  {à}{{\`a}}1 {è}{{\`e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
  {À}{{\`A}}1 {È}{{\'E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
  {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1
  {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1
  {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
  {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
  {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
  {ű}{{\H{u}}}1 {Ű}{{\H{U}}}1 {ő}{{\H{o}}}1 {Ő}{{\H{O}}}1
  {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1
  {€}{{\euro}}1 {£}{{\pounds}}1 {«}{{\guillemotleft}}1
  {»}{{\guillemotright}}1 {ñ}{{\~n}}1 {Ñ}{{\~N}}1 {¿}{{?`}}1
}

\begin{document}

\titulo{Informe de Trabajo Pr\'actico 1}
\subtitulo{Subset Sum Problem}
\fecha{Domingo 16 de Septiembre de 2018}
\materia{Algoritmos y Estructuras de Datos III}
\grupo{}
\newcommand{\senial}{\textit{se\~nal}}
\newcommand{\amplitud}{\textit{amplitud}}
\newcommand{\tiempo}{\textit{tiempo}}
\newcommand{\intervalo}{\textit{intervalo}}

% Pongan cuantos integrantes quieran
\integrante{Springhart, Gonzalo}{308/17}{glspringhart@gmail.com}

\maketitle

\section*{Introducci\'on}

En este informe vamos a comparar a eficiencia de distintos algoritmos utilizados para resolver un problema conocido como \textit{Subset Sum Problem} (o Problema de suma de subconjuntos). El mismo consiste en lo siguiente, dado un conjunto $S$ de $n$ elementos, cada uno con un valor asociado $v_i$ y un valor objetivo $V$, se quiere saber si existe un subconjunto de \'items de $S$ que sumen exactamente el valor objetivo, y si existe dicho subconjunto, se quiere saber cu\'al es la m\'inima cardinalidad entre todos los subconjuntos posibles, en otras palabras, hay que decidir si existe $R \subseteq S$ tal que $\sum_{i \in R} vi = V$. Se asumen tambi\'en que los valores de $S$ son enteros no negativos (aunque el problema se puede resolver también sin necesidad de esta restricci\'on).
%INSERTAR ACA EJEMPLOS DEL PROBLEMAAAAAAAAAAAA
\\
El objetivo es ver cu\'al de los algoritmos es m\'as eficiente al resolver el problema, se van a presentar 4 algoritmos que resuelven el problema, indicando como funcionan, justificando sus complejidades y comprobando a trav\'ez de experimentos que estas complejidades son ciertas.

\section{Algoritmos y justificaci\'on de complejidades}

Se va a usar la siguiente notaci\'on:
\begin{itemize}
	\item $S$ es el conjunto, que tiene $n$ elementos, cada uno con un valor asociado $v_i$ con $i \in \{1,...,n\}$
	\item $V$ es el valor objetivo
\end{itemize}

\subsection{Fuerza Bruta}
El primer algoritmo presentado para resolver el problema es uno de \textit{Fuerza Bruta}, b\'asicamente el algoritmo genera todos los conjuntos posibles con los elementos de $S$ y se fija cu\'al de ellos tiene elementos tales que su suma de exactamente $V$, mientras los calcula se va quedando con el que tiene menor cardinalidad.
\\
El algoritmo implementado en este trabajo práctico es el siguiente:
\\
%ACA VA EL ALGO
\begin{algorithm}
\begin{algorithmic}
	\Procedure{subsetSumFuerzaBruta}{$S$, $V$}
		\State $longMinima \gets -1$
		%\State $partes \gets generarConjPartes(S)$\Comment{$O(2^n)$}
		\For{$contador$ de $0$ a $2^{|S|} - 1$}\Comment{Se ejecuta $2^{|S|}$ veces}
			\State $longActual \gets 0$
			\State $sumaTotal \gets 0$
				
			\For{$i$ de $0$ a $|S| - 1$} \Comment{Se ejecuta $|S|$ veces}
				\If{El $i$-esimo bit de $contador$ es $1$}
					\State $sumaTotal \gets sumaTotal + S[i]$
					\State $longActual \gets longActual + 1$
				\EndIf
			\EndFor
			
			\If{$sumaTotal == V$}\Comment{Toda esta parte es $O(1)$}
				\If{$longMinima == -1$}
					\State $longMinima \gets longActual$
				\Else
					\State $longMinima \gets min(longMinima, longActual)$
				\EndIf
			\EndIf
		\EndFor
		
		\Return{$longMinima$}
	\EndProcedure
\end{algorithmic}
\end{algorithm}

Este algoritmo genera todos los subconjuntos del conjunto partes de $S$ de la siguiente forma, podemos interpretar cada subconjunto de $S$ como un conjunto donde algunos elementos de $S$ están y otros no. Entonces si pensamos a cada elemento como un bit donde 0 indica que el elemento no esta y 1 que si, podemos ver que con $|S|$ bits nos alcanza para generar todos los subconjuntos del conjunto partes de $S$.
\\
El algoritmo ejecuta un ciclo que incrementa un contador (que usamos para saber en que subconjunto está) $2^{|S|}$ veces, dentro de cada ciclo se fija el valor de cada bit de contador (que tiene $|S|$ bits) y suma los elementos de $S$ que correspondan a la posición del bit que valga 1, entonces como mucho se suman $|S|$ elementos, las operaciones para calcular el m\'inimo despu\'es de hacer la suma son $O(1)$.
\\
Entonces la complejidad del algoritmo es $O(|S| * 2^|S|) = O(n * 2^n)$.

\subsection{Backtracking}
El Backtracking es un algoritmo que se utiliza para encontrar todas o algunas de las soluciones de alg\'un problema, se basa en ir armando la soluci\'on correcta al problema desechando las que no pueden ser correctas a medida que se ejecuta, lo que se conoce como poda, existen podas de \textbf{factibilidad}, que son las que se realizan cuando se sabe que la rama de soluciones no puede llegar al resultado y podas de \textbf{optimalidad} que se realiza para eliminar ramas que si bien llegan a una solución, se sabe que no es la optima.
Esa característica de desechar soluciones que no pueden ser correctas lo hace superior a probar todas las posibles.
\\
El algoritmo de backtracking implementado en este trabajo es el siguiente:

\begin{algorithm}
\begin{algorithmic}
	\Procedure{subsetSumBacktracking}{$S$, $V$}
		\State $ordenar(S)$ \Comment{Uso un ordenamiento que sea $O(n*log(n))$}
		
		\State \Return $subsetSumBacktrackingAUX(S, V, 0, 0, 0)$
	\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\begin{algorithmic}
	\Procedure{subsetSumBacktrackingAUX}{$S$, $V$, $inicio$, $longActual$, $sumActual$, $tamMejorConj$}
		\If{$inicio == |S|$}
			\If{$sumActual == V$}
				\State $tamMejorConj \gets minPos(tamMejorConj, longActual)$
				\State \Return $longActual$
			\Else
				\State \Return $-1$
			\EndIf
		\Else
			\If{$not (tamMejorConj == -1) \land longActual >= tamMejorConjunto$}
				\State \Return $-1$
			\EndIf
			
			\If{$sumActual == V$}
				\State $tamMejorConj \gets minPos(tamMejorConj, longActual)$
				\State \Return $minPos(longActual,subsetSumBacktrackingAUX(S,V,inicio,longActual-1,sumActual-S[inicio-1]))$
			\ElsIf{$sumActual > V$}
				\State \Return $-1$
			\ElsIf{$sumActual == sumActual + S[inicio]$}
				\State \Return $subsetSumBacktrackingAUX(S, V, inicio + 1, longActual, sumActual)$
			\Else
				\State \Return $minPos(subsetSumBacktrackingAUX(S,V,inicio+1, longActual+1, sumActual + S[inicio]), subsetSumBacktrackingAUX(S,V,inicio+1, longActual, sumActual))$
			\EndIf
		\EndIf
	\EndProcedure
\end{algorithmic}
\end{algorithm}

El algoritmo implementado de forma recursiva aque resuelve el problema funciona de la siguiente forma, cada elemento de $S$ puede estar o no en la solución, entonces en cada recursión pido el minimo entre tomar al elemento como parte de la solucion y no tomarlo. El caso base es cuando ya no quedan elementos para tomar, en ese caso se ve si la suma da o no y se devuelve la longitud correspondiente (-1 si no da y la longitud de la solucion si da). Si se alcanza al valor objetivo después de agregar a un elemento, compara la longitud de esa solución con la que no incluyo ese elemento haciendo recursión y se queda con la menor. $minPos(a, b)$ devuelve el menor entre a y b, si uno de los dos es negativo, devuelve el otro y si los dos son negativos devuelve a uno de los dos, de esa forma si no hay solución se puede devolver $-1$.
\\
Este algoritmo supone que $S$ esta ordenado de forma creciente, esto es importante para poder justificar una de las podas hechas. También supone que $tamMejorConj$ se pasa por referencia.
\\

La \textbf{poda de factibilidad} del algoritmo consiste en que, si la suma al agregar un elemento se pasa de $V$, entonces esa rama de solución nunca va a encontrar un subconjunto que lo sume, ya que al estar ordenado los elementos que siguen son mayores. El algoritmo posee dos \textbf{podas de optimalidad}, una se realiza cuando el elemento que se va a agregar conjunto de solucion es el 0, como un 0 no aporta nada a la suma, se saltea y se ve directamente el elemento siguiente.
La segunda poda es la siguiente, al encontrar una solución al problema, se guarda la longitud del subconjunto solución como la mejor solución hasta el momento, si en otra rama de ejecución veo que la longitud del candidato a solución es más larga o de igual tamaño que la guardada, entonces se que por esa rama nunca voy a encontrar una solución más optima, entonces corto esa rama.
\\

Para calcular la complejidad hay que ver como se van abriendo las llamadas recursivas, si ignoramos las podas (que no afectan este cálculo) podemos ver que en cada recursión se van realizando dos llamadas a la función, una si se incluye al elemento actual en la solución y una si no. De esa forma la cantidad de llamadas va aumentando de forma exponencial a medida que sigue la función, hasta que se terminen los elementos del conjunto. Si graficamos como se va ejecutando la función se va a formar un árbol completo (aunque varias hojas tendrían lo mismo). Por lo que la función se ejecuta $2^{|S|} = 2^n$ veces.
Por lo tanto la complejidad de este algoritmo es $O(|S|*log(|S|) + 2^|S|) = O(n*log(n) + 2^n) \in O(n*2^n)$.
 
\subsection{Programaci\'on Din\'amica Top Down}
La programación dinámica es un método de programación que se basa en resolver un problema dividiéndolo en subproblemas de forma recursiva y guardando resultados ya calculados para no volverlos a calcular. Para evitar resolver los mismos subproblemas existen dos estilos de programación dinámica, en esta sección se muestra un algoritmo en el estilo \textbf{Top Down}.
Este tipo de programación dinámica se parece mucho a como uno lo resolveria con recursión, se va partiendo el problema principal en subproblemas más pequeños, con la diferencia de que de realiza un proceso de \textbf{memoización}, o en otras palabras, se guardan los resultados en una tabla para buscarlos en lugar de calcularlos de nuevo.
\\
Para este algoritmo la tabla va a representar lo siguiente, las columas de la tabla representan un posible valor objetivo, mientras que las filas representan la cantidad de elementos usados de $S$ (empezando desde el primero), y en cada celda se guarda el cardinal del conjunto más chico que forma el valor objetivo que corresponde a la columna, así por ejemplo la posición [3][6] tiene guardado el cardinal de los subconjuntos más chico que usa los primeros 3 elementos de $S$ y suma $6$, en caso de no haber subconjunto que sume el valor de la columna, en la celda habrá un -1.
\\
Entonces el algoritmo queda así:

\begin{algorithm}
\begin{algorithmic}
	\Procedure{subsetSumPDTDRec}{$S$, $i$, $j$, $matriz$} \Comment{$matriz$ se pasa por referencia}
		\If{$i < 0$}
			\State \Return $-1$
		\EndIf
		\If{$j < 0$}
			\State \Return $-1$
		\EndIf
		\If{$j == 0$}
			\If{$matriz[i][j] != -10$}
				\State \Return $matriz[i][j]$
			\Else
				\State $matriz[i][j] \gets 0$
				\State \Return $matriz[i][j]$
			\EndIf
		\EndIf
		\If{$i == 0$}
			\If{$matriz[i][j] != -10$}
				\State \Return $matriz[i][j]$
			\Else
				\If{$j == 0$}
					\State $matriz[i][j] \gets 0$			
				\Else
					\If{$S[i] == j$}
						\State $matriz[i][j] \gets 1$
					\Else
						\State $matriz[i][j] \gets -1$
					\EndIf
				\EndIf
				\State \Return $matriz[i][j]$
			\EndIf
		\EndIf
		
		\If{$matriz[i][j] != -10$}
			\State \Return $matriz[i][j]$
		\Else
			\State $m1 \gets subsetSumPDTDRec(S, i-1, j, matriz)$ \Comment{Calculo el problema sin contar el elemento actual}
			\State $m2 \gets subsetSumPDTDRec(S, i-1, j - s[i], matriz)$ \Comment{Calculo el problema teniéndolo en cuenta}
			\If{$m1 == -1$ and $m2 == -1$}
				\State $matriz[i][j] \gets -1$
			\Else
				\If{$minPos(m1, m2) == m1$}
					\State $matriz[i][j] \gets m1$
				\Else
					\State $matriz[i][j] \gets m2 + 1$ \Comment{El mínimo vino de incluir el elemento, entonces la longitud es uno más de lo que devolvió el subproblema}
				\EndIf
			\EndIf
			
			\State \Return $matriz[i][j]$
		\EndIf
	\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\begin{algorithmic}
	\Procedure{subsetSumPDTD}{$S$, $V$}
		\State $matriz \gets$ matriz de $|S|$ filas y $V+1$ columnas con $-10$ en cada valor \Comment{Esto es $O(|S|*V) = O(n*V)$}
		\State $subsetSumPDTDRec(S, |S|-1, V, matriz)$ \Comment{La matriz se pasa por referencia}
		\State \Return $matriz[|S|-1][V]$
	\EndProcedure
\end{algorithmic}
\end{algorithm}

%Acá va la justificación de la complejidad
\pagebreak

%Vamos a Explicarlo con la matriz
Este algoritmo llega a la solución usando la misma idea del de que el de backtracking, tomando el minimo entre la solución que incluye el elemento actual y el que no, así se van partiendo los subproblemas hasta llegar a los casos base, que son cuando se pasen las dimensiones de la matriz que resulta en un $-1$ y cuando se llega a la columna $0$ donde se devuelve 0.
También se va ejecutando de forma parecida al de backtracking, se van haciendo dos llamados a funciones en cada recursión, pero estas recursiones sólo se realizan una vez, si en la matriz hay un $-10$ entonces ese valor no fue computado y se calcula. Pero una vez calculado, se guarda y se se pide entonces se accede directamente al guardado. 
%También la recursión se realiza sobre el tamaño de la matriz, por lo que esta acotada por $O(|S|*V) = O(n*V)$.

%Veamos que la complejidad del algoritmo es la correcta, hay un ciclo que crea la matriz donde se van a guardar los datos, este ciclo cuesta $O(N*V)$. La función recursiva que calcula la solución lo hace de la siguiente manera, en cada ejecución que no llegue al caso base, se realizan dos llamadas recursivas para calcular los distintos posibles resultados, estas llamadas van tomando parámetros que causan que la matriz utilizada para guardar los datos se vaya cargando, si bien el algoritmo pasa por todas las filas de la matriz, no necesariamente pasa por todas las columnas de cada fila. La llamada recursiva que incluye al elemento actual en la solución le resta al valor objetivo ese elemento, ese cambio en el valor objetivo va a provocar un salto hacia otra columna de la matriz en la rama, efectivamente salteando la carga de celdas.
%
%%Meter acá un dibujo o algo asi !!!!!!!!!!!!!!!!!!!!
%
%El salto más corto que puede hacer el algoritmo es una unidad, por lo que si en todas las ramas donde el algoritmo salta, solo salta 1 vez entonces se calcula a lo sumo la mitad de la matriz, ya que en cada llamada recursiva se calcula la celda de arriba y la de arriba a la izquierda de la actual, y no se calculan las celdas que esten directamente a la izquierda o a la derecha de la actual.
%
%%Meter acá un dibujo de la matriz cargada a la mitad.
%
%Como el algoritmo para al pasarse de las dimensiones de la matriz, la función recursiva es $O(N*V)$, ya que ese es el tamaño de la matriz que el algoritmo va llenando.
%
%Entonces el algoritmo es $O(N*V)$

Vamos a ver que la complejidad del algoritmo es la pedida, primero se carga la matriz donde guardamos los resultados para no calcularlos de nuevo, eso es $O(N*V)$, ahora veamos que el resto da también $O(N*V)$.
La función recursiva del algortimo se mueve por la matriz utilizando dos parámetros, $i$ y $j$, $i$ está acotado por $|S| = N$ y $j$ esta acotado por $V$, como el valor mínimo que puede tomar cada uno es 0 (cuando alguna de las dos es $<= 0$ se llega a un caso base), entonces por las combinaciones posibles que pueden tomar los parametros, la funcion se llama a lo sumo $N*V$ veces. Ahora veamos los pesos de las llamadas recursivas, si la solución que busca la llamada no fue calculada anteriormente, 	entonces se van a realizar llamadas que eventualmente llegan a los casos base, que son $O(1)$, luego se realizan operaciones $O(1)$ para calcular el máximo valor devuelto por las llamadas recursivas y guardarlo en la matriz. Si la solución que busca ya había sido calculada entonces se obtiene la solución en $O(1)$ accediendo a la matriz. Entonces las llamadas recursivas son $O(1)$ y como a lo sumo se realizan $O(N*V)$ llamadas por lo dicho anteriormente.
Si juntamos las complejidades entonces tenemos $O(N*V) + O(N*V) = O(2*N*V) = O(N*V)$. Y entonces la complejidad del algoritmo es $O(N*V)$.

\subsection{Programaci\'on Din\'amica Bottom Up}

El otro estilo de Programación Dinámica se conoce como \textbf{Bottom Up}, en lugar de resolver el problema partiendolo en subproblemas, va resolviendo los subproblemas primero y llega a la solución del problema principal.
\\
En lugar de utilizar la recursión directamente, deducimos de ésta una formula que nos permita ir llenando la misma matriz que se uso en el algoritmo Top Down de forma directa. Y al final de devuelve la celda correspondiente de la matriz.
\\
El algoritmo es el siguiente:

\begin{algorithm}
\begin{algorithmic}
	\Procedure{subsetSumPDBU}{$S$, $V$}
		\State $matriz \gets$ crear matriz de $|S|$ filas y $V+1$ columnas
		\For{$i$ de $0$ a $|S| - 1$}
			\State $matriz[i][0] \gets 0$
		\EndFor
		\For{$j$ de $0$ a $V$}
			\If{$S[0] == j$}
				\State $matriz[0][j] \gets 1$
			\Else
				\State $matriz[0][j] \gets -1$
			\EndIf
		\EndFor
		\For{$i$ de $1$ a $|S| - 1$}
			\For{$j$ de $1$ a $V$}
			\State $m1 \gets matriz[i-1][j]$			
			\If{$j - S[i] < 0$}
				\State $m2 \gets -1$
			\Else
				\State $m2 \gets matriz[i-1][j - S[i]]$
			\EndIf
			\If{$minPos(m1, m2) == m1$}
				\State $matriz[i][j] \gets m1$ \Comment{S[i] no es parte de la solución}
			\Else
				\State $matriz[i][j] \gets m2 + 1$ \Comment{S[i] es parte de la solución, hay que sumar 1}
			\EndIf
			\EndFor
		\EndFor
		
		\State \Return $matriz[|S|-1][V]$
	\EndProcedure
\end{algorithmic}
\end{algorithm}

En este algoritmo la matriz se interpreta igual que en el anterior, las columnas son posibles valores objetivos y las filas son la cantidad de elementos (tomados desde el primero) del conjunto, el valor de toda la columna $0$ va a ser $0$, ya que dado cualquier conjunto $S$, el conjunto vacío es un subconjunto de $S$ y la suma de sus elementos es $0$. En la primera fila todos las columnas van a tener $-1$ cuando el número de la columna no sea igual al primer elemento de $S$ y $1$ cuando sea. Basándonos en la recursión podemos ver que tomando un elemento, la menor cardinal de un subconjunto que suma $V$ es la mínima cardinal entre el conjunto que suma $V$ y no incluya al elemento actual y la cardinal del conjunto que suma $V$ e incluye el elemento actual de $S$. Entonces para una celda ($i$, $j$) la cardinal va a ser el mínimo entre ($i-1$, $j$) y
($i-1$, $j-S[i]$), si ambos son negativos entonces el cardinal es $-1$. Si el cardinal mínimo es el de ($i-1$, $j-S[i]$), entonces hay que sumarle $1$ para que tome en cuenta la inclusión del elemento $S[i]$ en la solución. Entonces la solución al problema se encontraría en la celda ($|S|-1$, $V$).
\\
La complejidad de este algoritmo es simple de calcular, podemos ignorar la complejidad de los dos primeros ciclos ya que la que realmente pesa es la del tercero, que se ejecuta $|S|-1 * V$ veces, lo que significa que es $O(|S|*V)$.
\\
Entonces el algoritmo es $O(|S|*V) = O(n*V)$.

\pagebreak

\section{Experimentos}
%CAMBIAAAAAAAAAR ESTOOOOOOOOOO
%FALTA (En esta sección):
%	Hacer subsecciones para cada exp.
%	Experimentos para probar que la complejidad da lo que dije
%	Experimentos que muestren en qué casos sirve cada algoritmo
%	Sacar el grafico ese donde puse a todas juntas, comparar quiza a backtracking y a Brute Force pero a las 4 
%   juntas no porque no hay manera.

Como fue mencionado anteriormente nos interesa saber cuál de los algoritmos es más eficiente para resolver el \textit{Subset Sum Problem}, por los cálculos de complejidad anteriormente realizados podemos intuir que los algoritmos de programación dinámica son los que van a tener ventaja sobre la fuerza bruta y el backtracking.
\\
%Para poder apreciar las diferencias entre ellos, se diseño un caso de test que prueba el tiempo que tardan los algoritmos en su peor caso, para la Fuerza Bruta no existe realmente un peor caso ya que siempre se fija en todos los subconjuntos posibles, al algoritmo Bottom Up le sucede algo parecido, como siempre genera toda la tabla, no hay un valor de entrada que le haga hacer más o menos pasos, sin embargo es afectado junto con el Top Down por el valor de $V$, entonces el peor caso se basó en el de Backtracking y el Top Down. 
%\\
%El peor caso de Backtracking consiste en evitar las podas que lo optimizan, por ende las entradas que van a dar el peor caso son: un conjunto tal que ningun elemento sea 0 y un valor objetivo tal que sea mayor que la suma de todos los elementos del conjunto. De esa forma se evitan las podas y el algoritmo tiene que calcular todas las ramas.
%\\
%El peor caso del algoritmo Top Down seria un conjunto cuyos elementos sean todos 1, ya que provocaría que la recursión tome más pasos para llegar a los casos base, y por ende tome más tiempo.
%\\
%Utilizando un script hecho en python se fueron creando inputs que cumplen esta característica, que después procesó una versión modificada del programa del TP para generar outputs, que se leen desde jupyter notebooks para poder generar los gráficos.
%\\
%Despúes de realizar varios experimentos surgió un problema, aunque se construyo un peor caso para podes comparar a los algoritmos, los de programación dinámica resultaron ser mucho más eficientes que lo esperado. En el siguiente gráfico se aumento el tamaño del conjunto dejando a $V$ fija en un número arbitrariamente alto:
%\\
%\begin{center}
%	\includegraphics[width=.8\linewidth]{G3.pdf}
%\end{center}
%
%Si bien este gráfico no nos dice mucho de como son los dos algoritmos de programación dinámica, nos ayuda a ver que aún tomando datos de $V$ grandes son mejores que la Fuerza Bruta y Backtracking. El tamaño del conjunto no llega a crecer mucho ya que como la Fuerza Bruta pasa por todos los subconjuntos de partes de $S$ la cantidad de pasos que tiene que realizar crece demasiado rápido, al punto de que no alcanza la memoria del sistema para poder calcularlos, esto no pasa de la misma forma con los otros algoritmos.
%\\

\subsection{Experimentos sobre complejidad}
Antes de comparar los algoritmos vamos a ver que las complejidades calculadas para cada uno sean las correctas, si tomamos los resultados en tiempo que nos va dando cada algoritmo y los dividimos por la función que representa la complejidad de cada uno, el resultado debería dar acercase a $1$, o ir decreciendo si el algoritmo es de menor complejidad. Si graficamos esto entonces deberíamos obtener una linea parecida a una función constante o una función lineal decreciente.

\subsection{Backtracking vs Fuerza Bruta}

\subsection{Comparación entre algoritmos de programación dinámica}

%REHACER ESTE
Ya que los algoritmos Top Down y Bottom Up resultaron mejores, nos interesaría saber cuál de ellos es mejor, para eso se hicieron dos experimentos, uno donde se altera la cantidad de elementos del conjunto y otro donde se altera el valor objetivo del problema.
\\
El primer experimento produjo el suguiente gráfico:

\begin{center}
	\includegraphics[width=.8\linewidth]{G2.pdf}
\end{center}

Y el segundo produjo este:

\begin{center}
	\includegraphics[width=.8\linewidth]{G4.pdf}
\end{center}

De estos gráficos podemos ver que a la larga el algoritmo Bottom Up es el que termina resolviendo el problema en menos tiempo, pero lo que es más interesante es que los dos algoritmos tienden a tardar más a media que aumenta el valór $V$ que si aumenta la cantidad de elementos en el conjunto. En el caso del algoritmo Top Down, en el primér gráfico se ve que llega a tardar como mucho unos $4.5$ segundos mientras que en el segundo se ve que se pasa de los $5$ segundos en una ocasión.
\\
Esto puede estar sucediendo porque el algoritmo Top Down depende del valor $V$ para ir llegando a los casos base, mientras que el Bottom Up llena su matriz siempre al mismo paso, aunque esto le saque ventaja cuando $V$ no es muy grande.

Luego de la experimentación podemos concluir que el algoritmo más óptimo para resolver el problema de Subset Sum en general es el Bottom Up, aunque los otros métodos podrían ser utilizados si se tiene conocimiento sobre cuales van a ser los datos de entrada, por ejemplo si se supiera que el conjunto va a tener muchos 0 el algoritmo de Backtracking podría ser utilizado y aún se obtendrian resultados en tiempos rápidos.

\subsection{Casos de uso para los algoritmos}


%\section{Conclusiones}
%Acá van las conclusiones (si las hay)

%\section{Código}

%\lstinputlisting[language=C++]{main.cpp}

\section{Cambios}

%Acá van los cambios con la version anterior

\end{document}
